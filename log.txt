Failed  - time_embed.0 Linear(in_features=320, out_features=1280, bias=True)
Failed  - time_embed.2 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.0.0 Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.1.0.in_layers.2 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.1.0.emb_layers.1 Linear(in_features=1280, out_features=320, bias=True)
Failed  - input_blocks.1.0.out_layers.3 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - input_blocks.1.1.proj_in Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.1.1.transformer_blocks.0.attn1.to_q Linear(in_features=320, out_features=320, bias=False)
Failed  - input_blocks.1.1.transformer_blocks.0.attn1.to_k Linear(in_features=320, out_features=320, bias=False)
Failed  - input_blocks.1.1.transformer_blocks.0.attn1.to_v Linear(in_features=320, out_features=320, bias=False)
Failed  - input_blocks.1.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - input_blocks.1.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=320, out_features=2560, bias=True)
Success - input_blocks.1.1.transformer_blocks.0.ff.net.2 Linear(in_features=1280, out_features=320, bias=True)
Success - input_blocks.1.1.transformer_blocks.0.attn2.to_q Linear(in_features=320, out_features=320, bias=False)
Success - input_blocks.1.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=320, bias=False)
Success - input_blocks.1.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=320, bias=False)
Success - input_blocks.1.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - input_blocks.1.1.proj_out Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.2.0.in_layers.2 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.2.0.emb_layers.1 Linear(in_features=1280, out_features=320, bias=True)
Failed  - input_blocks.2.0.out_layers.3 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.2.1.proj_in Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.2.1.transformer_blocks.0.attn1.to_q Linear(in_features=320, out_features=320, bias=False)
Failed  - input_blocks.2.1.transformer_blocks.0.attn1.to_k Linear(in_features=320, out_features=320, bias=False)
Failed  - input_blocks.2.1.transformer_blocks.0.attn1.to_v Linear(in_features=320, out_features=320, bias=False)
Failed  - input_blocks.2.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - input_blocks.2.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=320, out_features=2560, bias=True)
Success - input_blocks.2.1.transformer_blocks.0.ff.net.2 Linear(in_features=1280, out_features=320, bias=True)
Success - input_blocks.2.1.transformer_blocks.0.attn2.to_q Linear(in_features=320, out_features=320, bias=False)
Success - input_blocks.2.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=320, bias=False)
Success - input_blocks.2.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=320, bias=False)
Success - input_blocks.2.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - input_blocks.2.1.proj_out Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.3.0.op Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
Failed  - input_blocks.4.0.in_layers.2 Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.4.0.emb_layers.1 Linear(in_features=1280, out_features=640, bias=True)
Failed  - input_blocks.4.0.out_layers.3 Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - input_blocks.4.0.skip_connection Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.4.1.proj_in Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.4.1.transformer_blocks.0.attn1.to_q Linear(in_features=640, out_features=640, bias=False)
Failed  - input_blocks.4.1.transformer_blocks.0.attn1.to_k Linear(in_features=640, out_features=640, bias=False)
Failed  - input_blocks.4.1.transformer_blocks.0.attn1.to_v Linear(in_features=640, out_features=640, bias=False)
Failed  - input_blocks.4.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - input_blocks.4.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=640, out_features=5120, bias=True)
Failed  - input_blocks.4.1.transformer_blocks.0.ff.net.2 Linear(in_features=2560, out_features=640, bias=True)
Failed  - input_blocks.4.1.transformer_blocks.0.attn2.to_q Linear(in_features=640, out_features=640, bias=False)
Success - input_blocks.4.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=640, bias=False)
Success - input_blocks.4.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=640, bias=False)
Success - input_blocks.4.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - input_blocks.4.1.proj_out Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.5.0.in_layers.2 Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.5.0.emb_layers.1 Linear(in_features=1280, out_features=640, bias=True)
Failed  - input_blocks.5.0.out_layers.3 Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.5.1.proj_in Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.5.1.transformer_blocks.0.attn1.to_q Linear(in_features=640, out_features=640, bias=False)
Failed  - input_blocks.5.1.transformer_blocks.0.attn1.to_k Linear(in_features=640, out_features=640, bias=False)
Failed  - input_blocks.5.1.transformer_blocks.0.attn1.to_v Linear(in_features=640, out_features=640, bias=False)
Failed  - input_blocks.5.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - input_blocks.5.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=640, out_features=5120, bias=True)
Success - input_blocks.5.1.transformer_blocks.0.ff.net.2 Linear(in_features=2560, out_features=640, bias=True)
Failed  - input_blocks.5.1.transformer_blocks.0.attn2.to_q Linear(in_features=640, out_features=640, bias=False)
Success - input_blocks.5.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=640, bias=False)
Success - input_blocks.5.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=640, bias=False)
Success - input_blocks.5.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - input_blocks.5.1.proj_out Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Success - input_blocks.6.0.op Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
Failed  - input_blocks.7.0.in_layers.2 Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.7.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.7.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - input_blocks.7.0.skip_connection Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.7.1.proj_in Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.7.1.transformer_blocks.0.attn1.to_q Linear(in_features=1280, out_features=1280, bias=False)
Failed  - input_blocks.7.1.transformer_blocks.0.attn1.to_k Linear(in_features=1280, out_features=1280, bias=False)
Failed  - input_blocks.7.1.transformer_blocks.0.attn1.to_v Linear(in_features=1280, out_features=1280, bias=False)
Failed  - input_blocks.7.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.7.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=1280, out_features=10240, bias=True)
Success - input_blocks.7.1.transformer_blocks.0.ff.net.2 Linear(in_features=5120, out_features=1280, bias=True)
Failed  - input_blocks.7.1.transformer_blocks.0.attn2.to_q Linear(in_features=1280, out_features=1280, bias=False)
Success - input_blocks.7.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=1280, bias=False)
Success - input_blocks.7.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=1280, bias=False)
Failed  - input_blocks.7.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.7.1.proj_out Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.8.0.in_layers.2 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.8.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.8.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.8.1.proj_in Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.8.1.transformer_blocks.0.attn1.to_q Linear(in_features=1280, out_features=1280, bias=False)
Failed  - input_blocks.8.1.transformer_blocks.0.attn1.to_k Linear(in_features=1280, out_features=1280, bias=False)
Failed  - input_blocks.8.1.transformer_blocks.0.attn1.to_v Linear(in_features=1280, out_features=1280, bias=False)
Failed  - input_blocks.8.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.8.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=1280, out_features=10240, bias=True)
Success - input_blocks.8.1.transformer_blocks.0.ff.net.2 Linear(in_features=5120, out_features=1280, bias=True)
Failed  - input_blocks.8.1.transformer_blocks.0.attn2.to_q Linear(in_features=1280, out_features=1280, bias=False)
Success - input_blocks.8.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=1280, bias=False)
Success - input_blocks.8.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=1280, bias=False)
Success - input_blocks.8.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.8.1.proj_out Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - input_blocks.9.0.op Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
Failed  - input_blocks.10.0.in_layers.2 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.10.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.10.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.11.0.in_layers.2 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - input_blocks.11.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - input_blocks.11.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - middle_block.0.in_layers.2 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - middle_block.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - middle_block.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - middle_block.1.proj_in Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - middle_block.1.transformer_blocks.0.attn1.to_q Linear(in_features=1280, out_features=1280, bias=False)
Failed  - middle_block.1.transformer_blocks.0.attn1.to_k Linear(in_features=1280, out_features=1280, bias=False)
Failed  - middle_block.1.transformer_blocks.0.attn1.to_v Linear(in_features=1280, out_features=1280, bias=False)
Failed  - middle_block.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - middle_block.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=1280, out_features=10240, bias=True)
Success - middle_block.1.transformer_blocks.0.ff.net.2 Linear(in_features=5120, out_features=1280, bias=True)
Failed  - middle_block.1.transformer_blocks.0.attn2.to_q Linear(in_features=1280, out_features=1280, bias=False)
Success - middle_block.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=1280, bias=False)
Success - middle_block.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=1280, bias=False)
Failed  - middle_block.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - middle_block.1.proj_out Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - middle_block.2.in_layers.2 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - middle_block.2.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - middle_block.2.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.0.0.in_layers.2 Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.0.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.0.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.0.0.skip_connection Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.1.0.in_layers.2 Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.1.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.1.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.1.0.skip_connection Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.2.0.in_layers.2 Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.2.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.2.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.2.0.skip_connection Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.2.1.conv Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.3.0.in_layers.2 Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.3.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.3.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.3.0.skip_connection Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.3.1.proj_in Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.3.1.transformer_blocks.0.attn1.to_q Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.3.1.transformer_blocks.0.attn1.to_k Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.3.1.transformer_blocks.0.attn1.to_v Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.3.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.3.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=1280, out_features=10240, bias=True)
Success - output_blocks.3.1.transformer_blocks.0.ff.net.2 Linear(in_features=5120, out_features=1280, bias=True)
Failed  - output_blocks.3.1.transformer_blocks.0.attn2.to_q Linear(in_features=1280, out_features=1280, bias=False)
Success - output_blocks.3.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=1280, bias=False)
Success - output_blocks.3.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=1280, bias=False)
Success - output_blocks.3.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.3.1.proj_out Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.4.0.in_layers.2 Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.4.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.4.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.4.0.skip_connection Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.4.1.proj_in Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.4.1.transformer_blocks.0.attn1.to_q Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.4.1.transformer_blocks.0.attn1.to_k Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.4.1.transformer_blocks.0.attn1.to_v Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.4.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.4.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=1280, out_features=10240, bias=True)
Success - output_blocks.4.1.transformer_blocks.0.ff.net.2 Linear(in_features=5120, out_features=1280, bias=True)
Failed  - output_blocks.4.1.transformer_blocks.0.attn2.to_q Linear(in_features=1280, out_features=1280, bias=False)
Success - output_blocks.4.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=1280, bias=False)
Success - output_blocks.4.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=1280, bias=False)
Success - output_blocks.4.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.4.1.proj_out Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.5.0.in_layers.2 Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.5.0.emb_layers.1 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.5.0.out_layers.3 Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.5.0.skip_connection Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.5.1.proj_in Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.5.1.transformer_blocks.0.attn1.to_q Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.5.1.transformer_blocks.0.attn1.to_k Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.5.1.transformer_blocks.0.attn1.to_v Linear(in_features=1280, out_features=1280, bias=False)
Failed  - output_blocks.5.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.5.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=1280, out_features=10240, bias=True)
Success - output_blocks.5.1.transformer_blocks.0.ff.net.2 Linear(in_features=5120, out_features=1280, bias=True)
Failed  - output_blocks.5.1.transformer_blocks.0.attn2.to_q Linear(in_features=1280, out_features=1280, bias=False)
Success - output_blocks.5.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=1280, bias=False)
Success - output_blocks.5.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=1280, bias=False)
Failed  - output_blocks.5.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=1280, out_features=1280, bias=True)
Failed  - output_blocks.5.1.proj_out Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.5.2.conv Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.6.0.in_layers.2 Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.6.0.emb_layers.1 Linear(in_features=1280, out_features=640, bias=True)
Success - output_blocks.6.0.out_layers.3 Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.6.0.skip_connection Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.6.1.proj_in Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.6.1.transformer_blocks.0.attn1.to_q Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.6.1.transformer_blocks.0.attn1.to_k Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.6.1.transformer_blocks.0.attn1.to_v Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.6.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - output_blocks.6.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=640, out_features=5120, bias=True)
Success - output_blocks.6.1.transformer_blocks.0.ff.net.2 Linear(in_features=2560, out_features=640, bias=True)
Failed  - output_blocks.6.1.transformer_blocks.0.attn2.to_q Linear(in_features=640, out_features=640, bias=False)
Success - output_blocks.6.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=640, bias=False)
Success - output_blocks.6.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=640, bias=False)
Success - output_blocks.6.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - output_blocks.6.1.proj_out Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.7.0.in_layers.2 Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.7.0.emb_layers.1 Linear(in_features=1280, out_features=640, bias=True)
Failed  - output_blocks.7.0.out_layers.3 Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.7.0.skip_connection Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.7.1.proj_in Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.7.1.transformer_blocks.0.attn1.to_q Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.7.1.transformer_blocks.0.attn1.to_k Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.7.1.transformer_blocks.0.attn1.to_v Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.7.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - output_blocks.7.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=640, out_features=5120, bias=True)
Success - output_blocks.7.1.transformer_blocks.0.ff.net.2 Linear(in_features=2560, out_features=640, bias=True)
Failed  - output_blocks.7.1.transformer_blocks.0.attn2.to_q Linear(in_features=640, out_features=640, bias=False)
Success - output_blocks.7.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=640, bias=False)
Success - output_blocks.7.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=640, bias=False)
Failed  - output_blocks.7.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - output_blocks.7.1.proj_out Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.8.0.in_layers.2 Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.8.0.emb_layers.1 Linear(in_features=1280, out_features=640, bias=True)
Failed  - output_blocks.8.0.out_layers.3 Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.8.0.skip_connection Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.8.1.proj_in Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.8.1.transformer_blocks.0.attn1.to_q Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.8.1.transformer_blocks.0.attn1.to_k Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.8.1.transformer_blocks.0.attn1.to_v Linear(in_features=640, out_features=640, bias=False)
Failed  - output_blocks.8.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - output_blocks.8.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=640, out_features=5120, bias=True)
Failed  - output_blocks.8.1.transformer_blocks.0.ff.net.2 Linear(in_features=2560, out_features=640, bias=True)
Success - output_blocks.8.1.transformer_blocks.0.attn2.to_q Linear(in_features=640, out_features=640, bias=False)
Success - output_blocks.8.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=640, bias=False)
Success - output_blocks.8.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=640, bias=False)
Success - output_blocks.8.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=640, out_features=640, bias=True)
Failed  - output_blocks.8.1.proj_out Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.8.2.conv Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.9.0.in_layers.2 Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.9.0.emb_layers.1 Linear(in_features=1280, out_features=320, bias=True)
Success - output_blocks.9.0.out_layers.3 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.9.0.skip_connection Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.9.1.proj_in Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.9.1.transformer_blocks.0.attn1.to_q Linear(in_features=320, out_features=320, bias=False)
Failed  - output_blocks.9.1.transformer_blocks.0.attn1.to_k Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.9.1.transformer_blocks.0.attn1.to_v Linear(in_features=320, out_features=320, bias=False)
Failed  - output_blocks.9.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - output_blocks.9.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=320, out_features=2560, bias=True)
Success - output_blocks.9.1.transformer_blocks.0.ff.net.2 Linear(in_features=1280, out_features=320, bias=True)
Success - output_blocks.9.1.transformer_blocks.0.attn2.to_q Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.9.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=320, bias=False)
Success - output_blocks.9.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=320, bias=False)
Success - output_blocks.9.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - output_blocks.9.1.proj_out Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.10.0.in_layers.2 Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.10.0.emb_layers.1 Linear(in_features=1280, out_features=320, bias=True)
Failed  - output_blocks.10.0.out_layers.3 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Success - output_blocks.10.0.skip_connection Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.10.1.proj_in Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.10.1.transformer_blocks.0.attn1.to_q Linear(in_features=320, out_features=320, bias=False)
Failed  - output_blocks.10.1.transformer_blocks.0.attn1.to_k Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.10.1.transformer_blocks.0.attn1.to_v Linear(in_features=320, out_features=320, bias=False)
Failed  - output_blocks.10.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - output_blocks.10.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=320, out_features=2560, bias=True)
Success - output_blocks.10.1.transformer_blocks.0.ff.net.2 Linear(in_features=1280, out_features=320, bias=True)
Success - output_blocks.10.1.transformer_blocks.0.attn2.to_q Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.10.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=320, bias=False)
Success - output_blocks.10.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=320, bias=False)
Success - output_blocks.10.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - output_blocks.10.1.proj_out Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.11.0.in_layers.2 Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.11.0.emb_layers.1 Linear(in_features=1280, out_features=320, bias=True)
Failed  - output_blocks.11.0.out_layers.3 Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
Failed  - output_blocks.11.0.skip_connection Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.11.1.proj_in Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - output_blocks.11.1.transformer_blocks.0.attn1.to_q Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.11.1.transformer_blocks.0.attn1.to_k Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.11.1.transformer_blocks.0.attn1.to_v Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.11.1.transformer_blocks.0.attn1.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - output_blocks.11.1.transformer_blocks.0.ff.net.0.proj Linear(in_features=320, out_features=2560, bias=True)
Success - output_blocks.11.1.transformer_blocks.0.ff.net.2 Linear(in_features=1280, out_features=320, bias=True)
Success - output_blocks.11.1.transformer_blocks.0.attn2.to_q Linear(in_features=320, out_features=320, bias=False)
Success - output_blocks.11.1.transformer_blocks.0.attn2.to_k Linear(in_features=768, out_features=320, bias=False)
Success - output_blocks.11.1.transformer_blocks.0.attn2.to_v Linear(in_features=768, out_features=320, bias=False)
Success - output_blocks.11.1.transformer_blocks.0.attn2.to_out.0 Linear(in_features=320, out_features=320, bias=True)
Failed  - output_blocks.11.1.proj_out Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
Failed  - out.2 Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
